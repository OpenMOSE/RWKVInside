1. Stage 1 Training for Qwen 0.5B with Norm
sh train.sh -c configs/qwen_0.5b.yaml -l 0.0001 -f 0.00001 -m 2048 -b 2 -r "/home/yueyulin/data/finemath/finemath-4plus/ /home/yueyulin/data/Mobius/standard/ /home/yueyulin/data/dclm-10B/ /home/yueyulin/data/additional_jsonl_cut/ " -o /home/yueyulin/model/qwen_0.5b_full_layers_stage1_v7_finemath  -g 1 -F 0 -d 1 -t 1000_000_000 -T 0.2 -R v7 -s 1 -M 1
sh train.sh -c configs/qwen_0.5b_one_attn.yaml -l 0.0001 -f 0.00001 -m 2048 -b 2 -r "/home/yueyulin/data/Magpie-Qwen2.5-Pro-1M-v0.1/data /home/yueyulin/data/finemath/finemath-4plus/ /home/yueyulin/data/Mobius/standard/ /home/yueyulin/data/dclm-10B/ /home/yueyulin/data/additional_jsonl_cut/ " -o /home/yueyulin/model/qwen_0.5b_stage1_with_mask_one_attn -R v7 -e 1
2. Stage 2 Training for Qwen 0.5B with Norm
sh train.sh -c configs/qwen_0.5b.yaml -l 0.0001 -f 0.00001 -m 2048 -b 2 -r "/home/yueyulin/data/Magpie-Qwen2.5-Pro-1M-v0.1/data /home/yueyulin/data/finemath/finemath-4plus/ /home/yueyulin/data/Mobius/standard/ /home/yueyulin/data/dclm-10B/ /home/yueyulin/data/additional_jsonl_cut/ " -o /home/yueyulin/model/qwen_0.5b_stage2_v7_finemath  -g 1 -F 0 -d 1 -t 1000_000_000 -T 0.2 -R v7 -s 2 -k /home/yueyulin/model/qwen_0.5b_full_layers_stage2_v7_finemath/pytorch_model.bin -M 1


2. Stage 2 Training for Qwen 0.5B with Norm and freez mlp
sh train.sh -c configs/qwen_0.5b.yaml -l 0.0001 -f 0.00001 -m 2048 -b 2 -r "/home/yueyulin/data/Magpie-Qwen2.5-Pro-1M-v0.1/data /home/yueyulin/data/finemath/finemath-4plus/ /home/yueyulin/data/Mobius/standard/ /home/yueyulin/data/dclm-10B/ /home/yueyulin/data/additional_jsonl_cut/ " -o /home/yueyulin/model/qwen_0.5b_stage2_v7_finemath  -g 1 -F 0 -d 1 -t 1000_000_000 -T 0.2 -R v7 -s 2 -k /home/yueyulin/model/qwen_0.5b_full_layers_stage2_v7_finemath/pytorch_model.bin -M 1 -z 1

2. Stage 2 Training for Qwen 0.5B without Norm and freez mlp
sh train.sh -c configs/qwen_0.5b.yaml -l 0.0001 -f 0.00001 -m 2048 -b 1 -r "/home/yueyulin/data/Magpie-Qwen2.5-Pro-1M-v0.1/data /home/yueyulin/data/finemath/finemath-4plus/ /home/yueyulin/data/Mobius/standard/ /home/yueyulin/data/dclm-10B/ /home/yueyulin/data/additional_jsonl_cut/ " -o /home/yueyulin/model/qwen_0.5b_stage2_with_mask -R v7 -e 1 -s 2 -d 1 -t 1000_000_000 -g 1 -k /home/yueyulin/model/qwen_0.5b_stage1_with_mask/pytorch_model.bin -z 1 

2. Stage 2 Training for Qwen 0.5B with Norm and freez mlp and use another teacher model
sh train.sh -c configs/qwen_0.5b.yaml -l 0.0001 -f 0.00001 -m 2048 -b 2 -r "/home/yueyulin/data/Magpie-Qwen2.5-Pro-1M-v0.1/data /home/yueyulin/data/finemath/finemath-4plus/ /home/yueyulin/data/Mobius/standard/ /home/yueyulin/data/dclm-10B/ /home/yueyulin/data/additional_jsonl_cut/ " -o /home/yueyulin/model/qwen_0.5b_stage2_v7_finemath  -g 1 -F 0 -d 1 -t 1000_000_000 -T 0.2 -R v7 -s 2 -k /home/yueyulin/model/qwen_0.5b_full_layers_stage2_v7_finemath/pytorch_model.bin -M 1 -z 1 -i /home/yueyulin/models/Qwen2.5-7B-Instruct/


1. Stage 1 Training Qwen7B-R1
nohup sh train.sh -c configs/qwen_7b_r1.yaml -l 0.0001 -f 0.00001 -m 2048 -b 8 -r "/data/yueyu/mysft/ /data/yueyu/additional_jsonl/split_files/ /data/yueyu/additional_jsonl/raw_splits/ /data/yueyu/chinese-fineweb-edu/data/ /data/yueyu/dclm-10B/ /data/yueyu/finemath-4plus /data/yueyu/Magpie-Qwen2.5-Pro-1M-v0.1/data/" -o /data/yueyu/output/7B_V7_Stage1_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD -g 1 -F 0 -d 1 -t 4000_000_000 -T 0.2 -R v7 -s 1 -G 8 -D hybrid_trainer_H800 -P 7B_V7_Stage1_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD -e 1 -z 1 > /data/yueyu/7B_V7_Stage1_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD.txt 2>&1 &

2. Stage 2 Training Qwen7B-R1
nohup sh train.sh -c configs/qwen_7b_r1.yaml -l 0.0001 -f 0.00001 -m 2048 -b 8 -r "/data/yueyu/mysft/ /data/yueyu/additional_jsonl/split_files/ /data/yueyu/additional_jsonl/raw_splits/ /data/yueyu/chinese-fineweb-edu/data/ /data/yueyu/dclm-10B/ /data/yueyu/finemath-4plus /data/yueyu/Magpie-Qwen2.5-Pro-1M-v0.1/data/" -o /data/yueyu/output/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD -g 1 -F 0 -d 1 -t 2000_000_000 -T 0.2 -R v7 -s 2 -G 8 -D hybrid_trainer_H800 -P 7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD -e 1 -z 1 -k /data/yueyu/output/7B_V7_Stage1_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD/pytorch_model.bin > /data/yueyu/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD.txt 2>&1 &

2.1 Stage 2 with data only from R1
nohup sh train.sh -c configs/qwen_7b_r1.yaml -l 0.0001 -f 0.00001 -m 2048 -b 8 -r "/data/yueyu/KL_DATA/2K/" -o /data/yueyu/output/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_2K -g 1 -F 0 -d 1 -t 2000_000_000_000 -T 0.2 -R v7 -s 2 -G 8 -D hybrid_trainer_H800 -P 7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_2K -e 1 -z 1 -k /data/yueyu/output/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD/pytorch_model.bin > /data/yueyu/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_2K.txt 2>&1 &

2.2 Stage 2 with data only from R1 - 4K
nohup sh train.sh -c configs/qwen_7b_r1.yaml -l 0.0001 -f 0.00001 -m 4096 -b 4 -r "/data/yueyu/KL_DATA/4K/" -o /data/yueyu/output/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_4K -g 1 -F 0 -d 1 -t 2000_000_000_000 -T 0.2 -R v7 -s 2 -G 8 -D hybrid_trainer_H800 -P 7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_4K -e 1 -z 1 -k /data/yueyu/output/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_2K/pytorch_model.bin > /data/yueyu/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_4K.txt 2>&1 &


2.2 Stage 2 with data only from R1 - 8K
nohup sh train.sh -c configs/qwen_7b_r1.yaml -l 0.0001 -f 0.00001 -m 8192 -b 2 -r "/data/yueyu/KL_DATA/8K/" -o /data/yueyu/output/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_8K -g 1 -F 0 -d 1 -t 2000_000_000_000 -T 0.2 -R v7 -s 2 -G 8 -D hybrid_trainer_H800 -P 7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_8K -e 1 -z 1 -k /data/yueyu/output/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_4K/pytorch_model.bin > /data/yueyu/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_8K.txt 2>&1 &

2.3 Stage 2 with data only from R1 - 16K
nohup sh train.sh -c configs/qwen_7b_r1.yaml -l 0.0001 -f 0.00001 -m 16384 -b 1 -r "/data/yueyu/KL_DATA/16K/" -o /data/yueyu/output/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_16K -g 1 -F 0 -d 1 -t 2000_000_000_000 -T 0.2 -R v7 -s 2 -G 8 -D hybrid_trainer_H800 -P 7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_16K -e 1 -z 1 -k /data/yueyu/output/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_8K/pytorch_model.bin > /data/yueyu/7B_V7_Stage2_FixVFirstShare_ATTENTIONMASK_NONORM_NOGATE_FREEMLP_R1_LEFTPAD_16K.txt 2>&1 &